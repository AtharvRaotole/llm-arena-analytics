# Data Sources Guide: Demo vs Real Data

## ğŸ“Š Current Data Status

### What's Using Demo/Fallback Data?

1. **Arena Scraper** (`chatbot_arena_scraper.py`)
   - âš ï¸ **Has fallback data** if real scraping fails
   - âœ… **Tries real scraping first** from multiple sources
   - ğŸ” **Fallback triggers when:**
     - Website structure changes
     - Network issues
     - API endpoints unavailable

2. **Pricing Scraper** (`pricing_scraper.py`)
   - âš ï¸ **Has fallback data** if real scraping fails
   - âœ… **Tries real scraping first** from provider websites
   - ğŸ” **Fallback triggers when:**
     - Website structure changes
     - Rate limiting
     - Network issues

3. **Historical Data** (`seed_historical_data.py`)
   - âš ï¸ **Generates synthetic data** for testing
   - âœ… **Uses realistic patterns** (random walk, trends)
   - ğŸ“ **Purpose:** Testing visualizations and ML models

4. **Market Sentiment**
   - âœ… **Hacker News:** Real data (no API needed)
   - â³ **Reddit:** Real data (after API approval)
   - âŒ **Twitter:** Not implemented

---

## ğŸ”„ How to Use REAL Data

### Step 1: Run Arena Scraper (Real Data)

```bash
docker-compose exec backend bash
cd /app/scrapers
python scraper_pipeline.py
```

**What it does:**
- Scrapes real Chatbot Arena leaderboard
- Inserts new models if found
- Updates scores for today
- Skips duplicates (unless `--force`)

**Check if using real data:**
```bash
# Check the logs - should see:
# "Starting leaderboard scrape"
# "Successfully scraped X models"
# NOT "Using known model data as fallback"
```

### Step 2: Run Pricing Scraper (Real Data)

```bash
docker-compose exec backend bash
cd /app/scrapers
python pricing_scraper.py
```

**What it does:**
- Scrapes OpenAI, Anthropic, Google pricing pages
- Extracts real current prices
- Stores in database

**Check if using real data:**
- Look for actual price values matching current market rates
- Fallback prices are outdated approximations

### Step 3: Run Sentiment Scraper (Real Data)

```bash
docker-compose exec backend bash
cd /app/scrapers
python sentiment_scraper.py --days 30
```

**What it does:**
- Scrapes Hacker News (real data, no API needed)
- Scrapes Reddit (if credentials provided)
- Stores in `market_sentiment` table

---

## ğŸ§ª Testing: What You Should See

### 1. Frontend Dashboard (http://localhost:8501)

#### Leaderboard Page:
- âœ… **Table with 10-20 models**
- âœ… **Columns:** Rank, Model, Provider, Score
- âœ… **Scores:** 1100-1300 range (realistic ELO)
- âœ… **Providers:** OpenAI, Anthropic, Google, Meta, etc.
- âœ… **Refresh button** works

#### Performance Trends Page:
- âœ… **Line chart** showing score evolution
- âœ… **Date range picker** (default: last 30 days)
- âœ… **Model selector** (multiselect, max 5)
- âœ… **Statistics table** below chart

#### Cost Intelligence Page:
- âœ… **Interactive calculator** with sliders
- âœ… **Value score leaderboard** table
- âœ… **Price history chart** (last 90 days)
- âœ… **Recommendations** based on cost/score

#### Market Intelligence Page:
- âœ… **Future rankings prediction** table
- âœ… **Trend analysis** sparkline charts
- âœ… **Market events timeline** (anomalies)
- âœ… **Insights & recommendations** text

### 2. Backend API (http://localhost:8000/docs)

#### Test Endpoints:
```bash
# Health check
curl http://localhost:8000/health

# Leaderboard
curl http://localhost:8000/models/leaderboard

# Model history
curl http://localhost:8000/models/GPT-4%20Turbo/history?days=30

# Forecast
curl http://localhost:8000/forecast/rank?days_ahead=30
```

### 3. Database Content

```bash
docker-compose exec postgres psql -U postgres -d llm_arena_analytics

# Check models
SELECT COUNT(*) FROM models;
SELECT name, provider FROM models LIMIT 10;

# Check arena rankings
SELECT COUNT(*) FROM arena_rankings;
SELECT m.name, ar.elo_rating, ar.recorded_at 
FROM arena_rankings ar 
JOIN models m ON ar.model_id = m.id 
ORDER BY ar.recorded_at DESC 
LIMIT 10;

# Check pricing
SELECT COUNT(*) FROM pricing_data;
SELECT model_name, input_cost_per_token*1000 as input_per_1k, effective_date
FROM pricing_data
ORDER BY effective_date DESC
LIMIT 10;
```

---

## ğŸ” How to Verify Real vs Demo Data

### Arena Data:
**Real data indicators:**
- âœ… Scores match current Chatbot Arena leaderboard
- âœ… Model names are current (e.g., GPT-4 Turbo, Claude 3.5 Sonnet)
- âœ… Scores change daily when scraper runs
- âœ… Logs show "Successfully scraped X models"

**Demo data indicators:**
- âš ï¸ Logs show "Using known model data as fallback"
- âš ï¸ Scores don't match current leaderboard
- âš ï¸ Same scores every day

### Pricing Data:
**Real data indicators:**
- âœ… Prices match current provider websites
- âœ… Prices update when providers change them
- âœ… Accurate to 4 decimal places

**Demo data indicators:**
- âš ï¸ Prices are round numbers (approximations)
- âš ï¸ Prices never change
- âš ï¸ Missing newer models

### Historical Data:
**Synthetic data (for testing):**
- âš ï¸ Generated by `seed_historical_data.py`
- âœ… Realistic patterns (trends, seasonality)
- âœ… Used for ML training and visualizations
- ğŸ“ **This is intentional** - needed for testing

---

## ğŸš€ Daily Data Updates

### Automated Scraping (Recommended)

Create a cron job or scheduled task:

```bash
# Add to crontab (runs daily at 2 AM)
0 2 * * * cd /path/to/llm-arena-analytics && docker-compose exec -T backend bash -c "cd /app/scrapers && python scraper_pipeline.py"
```

Or use Docker's restart policy + scheduled script.

### Manual Updates

```bash
# Update arena data
docker-compose exec backend bash -c "cd /app/scrapers && python scraper_pipeline.py"

# Update pricing (weekly is fine)
docker-compose exec backend bash -c "cd /app/scrapers && python pricing_scraper.py"

# Update sentiment (daily)
docker-compose exec backend bash -c "cd /app/scrapers && python sentiment_scraper.py --days 1"
```

---

## ğŸ“ Summary

| Component | Current Status | Real Data? | How to Get Real Data |
|-----------|---------------|------------|---------------------|
| **Arena Scraper** | âœ… Working | âš ï¸ Fallback available | Run `scraper_pipeline.py` |
| **Pricing Scraper** | âœ… Working | âš ï¸ Fallback available | Run `pricing_scraper.py` |
| **Historical Data** | âœ… Working | âŒ Synthetic (intentional) | Keep synthetic for ML |
| **Sentiment (HN)** | âœ… Working | âœ… Real data | Run `sentiment_scraper.py` |
| **Sentiment (Reddit)** | â³ Waiting | âœ… Real (after API) | Add credentials |

---

## âœ… Quick Test Checklist

- [ ] Frontend loads at http://localhost:8501
- [ ] Leaderboard shows 10+ models
- [ ] Performance trends chart displays
- [ ] Cost Intelligence calculator works
- [ ] Market Intelligence predictions show
- [ ] API docs accessible at http://localhost:8000/docs
- [ ] Database has models, rankings, pricing
- [ ] Scrapers run without errors

---

## ğŸ› Troubleshooting

### If scrapers use fallback:
1. Check network connectivity
2. Verify website URLs are accessible
3. Check scraper logs for errors
4. Website structure may have changed (update scraper)

### If no data in dashboard:
1. Run seed script: `python seed_historical_data.py`
2. Run scrapers: `python scraper_pipeline.py`
3. Check database connection
4. Verify Docker containers are running

### If ML models don't work:
1. Ensure historical data exists (90+ days)
2. Run: `python performance_predictor.py`
3. Check `data/models/` directory for saved models

